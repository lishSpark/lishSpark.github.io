<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      SparkSQL | lish&#39;s blog 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="lish">
    
    

    <meta name="description" content="SparkSQL在spark内核的基础上提供了对结构化数据的处理，允许用户直接通过hive表，Parquet文件以及一些其他数据源生成的DataFrame，提高JDBC读写表的能力，可以原生支持Postgres,Mysql等系统。在Spark1.3中，引入了DataFrame来重命名SchemaRDD类型。">
<meta property="og:type" content="article">
<meta property="og:title" content="SparkSQL | lish's blog">
<meta property="og:url" content="http://yoursite.com/2016/06/13/SparkSQL/index.html">
<meta property="og:site_name" content="lish's blog">
<meta property="og:description" content="SparkSQL在spark内核的基础上提供了对结构化数据的处理，允许用户直接通过hive表，Parquet文件以及一些其他数据源生成的DataFrame，提高JDBC读写表的能力，可以原生支持Postgres,Mysql等系统。在Spark1.3中，引入了DataFrame来重命名SchemaRDD类型。">
<meta property="og:image" content="http://yoursite.com/images/sql.png">
<meta property="og:image" content="http://yoursite.com/images/SQL运行架构.png">
<meta property="og:updated_time" content="2016-06-13T11:21:27.108Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SparkSQL | lish's blog">
<meta name="twitter:description" content="SparkSQL在spark内核的基础上提供了对结构化数据的处理，允许用户直接通过hive表，Parquet文件以及一些其他数据源生成的DataFrame，提高JDBC读写表的能力，可以原生支持Postgres,Mysql等系统。在Spark1.3中，引入了DataFrame来重命名SchemaRDD类型。">
<meta name="twitter:image" content="http://yoursite.com/images/sql.png">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">lish&#39;s blog</a></h1>
        <hr class="panel-cover__divider" />

        
        <p class="panel-cover__description">
          welcome to here
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/loveCanopy" title="Huno on GitHub">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->



  </ul>
</nav>



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">SparkSQL</h1>

    

    <div class="post-meta">
      <time datetime="2016-06-13" class="post-meta__date date">2016-06-13</time> 

      <span class="post-meta__tags tags">

          
            <font class="categories">
            &#8226; 分类:
            <a class="categories-link" href="/categories/Spark/">Spark</a>
            </font>
          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/SQL/">SQL</a>, <a class="tags-link" href="/tags/Spark开发/">Spark开发</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <h1 id="SparkSQL"><a href="#SparkSQL" class="headerlink" title="SparkSQL"></a>SparkSQL</h1><p>在spark内核的基础上提供了对结构化数据的处理，允许用户直接通过hive表，Parquet文件以及一些其他数据源生成的DataFrame，提高JDBC读写表的能力，可以原生支持Postgres,Mysql等系统。<br>在Spark1.3中，引入了DataFrame来重命名SchemaRDD类型。<br><a id="more"></a><br>DataFrame功能特性：<br>1.多种数据格式和多种存储系统的支持<br>2.通过Spark SQL的Catalyst优化器进行先进的优化，生成代码<br>3.有KB到PB的数据集支持<br>SparkSQL的表数据在内存中存储不是采用原生态的JVM对象存储方式，而是采用内存列存储<br><img src="/images/sql.png" alt="SparkSQL"><br>该存储方式无论在空间占用量和读取吞吐率上都占有很大优势。</p>
<h2 id="SparkSQL运行架构"><a href="#SparkSQL运行架构" class="headerlink" title="SparkSQL运行架构"></a>SparkSQL运行架构</h2><p>类似于关系型数据库，SparkSQL也是语句也是由Projection（a1，a2，a3）、Data Source（tableA）、Filter（condition）组成，分别对应sql查询过程中的Result、Data Source、Operation，也就是说SQL语句按Result–&gt;Data Source–&gt;Operation的次序来描述的。<br><img src="/images/SQL运行架构.png" alt="SparkSQL运行"><br>当执行SparkSQL语句的顺序为：<br>1.对读入的SQL语句进行解析（Parse），分辨出SQL语句中哪些词是关键词（如SELECT、FROM、WHERE），哪些是表达式、哪些是Projection、哪些是Data Source等，从而判断SQL语句是否规范；<br>2.将SQL语句和数据库的数据字典（列、表、视图等等）进行绑定（Bind），如果相关的Projection、Data Source等都是存在的话，就表示这个SQL语句是可以执行的；<br>3.一般的数据库会提供几个执行计划，这些计划一般都有运行统计数据，数据库会在这些计划中选择一个最优计划（Optimize）；<br>4.计划执行（Execute），按Operation–&gt;Data Source–&gt;Result的次序来进行的，在执行过程有时候甚至不需要读取物理表就可以返回结果，比如重新运行刚运行过的SQL语句，可能直接从数据库的缓冲池中获取返回结果。</p>
<h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><p>1.通用加载数据源方式<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df = sqlContext.read.load(<span class="string">"examples/src/main/resources/users.parquet"</span>)</span><br><span class="line">df.select(<span class="string">"name"</span>, <span class="string">"favorite_color"</span>).write.save(<span class="string">"namesAndFavColors.parquet"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = sqlContext.read.load(<span class="string">"examples/src/main/resources/users.json"</span>)</span><br><span class="line">df.select(<span class="string">"name"</span>, <span class="string">"favorite_color"</span>).write.save(<span class="string">"namesAndFavColors.json"</span>)</span><br></pre></td></tr></table></figure></p>
<p>2.指定数据源方式<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df=sqlContext.load(<span class="string">"XXX.parquet"</span>,<span class="string">"parquet"</span>)</span><br><span class="line">df.save(<span class="string">"XXX.parquet"</span>,<span class="string">"parquet"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df=sqlContext.load(<span class="string">"XXX.json"</span>,<span class="string">"json"</span>)</span><br><span class="line">df.save(<span class="string">"XXX.json"</span>,<span class="string">"json"</span>)</span><br></pre></td></tr></table></figure></p>
<p>3.保存到持久化表中(存到系统上)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.saveAsTable(<span class="string">"tableName"</span>)</span><br></pre></td></tr></table></figure></p>
<p>4.保存到临时表中(应用退出销毁)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.registerTempTable(<span class="string">"tableName"</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">date:<span class="type">String</span>,session:<span class="type">String</span>,name:<span class="type">String</span>,c_seq:<span class="type">Int</span>,s_seq:<span class="type">Int</span>,url:<span class="type">String</span></span>)</span></span><br><span class="line">main主方法下</span><br><span class="line"><span class="keyword">val</span> conf=<span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"Spark-SQL"</span>)</span><br><span class="line"><span class="keyword">val</span> sc=<span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sqlcontext=<span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</span><br><span class="line"><span class="keyword">import</span> sqlcontext.implicits._</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> data=sc.textFile(<span class="string">"e:\\mllib\\SogouQ1.txt"</span>).map&#123;_.split(<span class="string">"\t"</span>)&#125;.map(s=&gt;<span class="type">Person</span>(s(<span class="number">0</span>),s(<span class="number">1</span>),s(<span class="number">2</span>),s(<span class="number">3</span>).trim().toInt,s(<span class="number">4</span>).trim().toInt,s(<span class="number">5</span>))).toDF()</span><br><span class="line"></span><br><span class="line">data.registerTempTable(<span class="string">"sogoudata"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="json文件"><a href="#json文件" class="headerlink" title="json文件"></a>json文件</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc: <span class="type">SparkContext</span> <span class="comment">// An existing SparkContext.</span></span><br><span class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</span><br><span class="line">...</span><br><span class="line">people.write.json(<span class="string">"people.json"</span>)</span><br><span class="line"><span class="comment">//加载json数据源</span></span><br><span class="line"><span class="keyword">val</span> df = sqlContext.read.json(<span class="string">"people.json"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//简单操作</span></span><br><span class="line">df.show()</span><br><span class="line">df.printSchema()  <span class="comment">// Print the schema in a tree format</span></span><br><span class="line">df.select(<span class="string">"name"</span>).show() </span><br><span class="line">df.filter(df(<span class="string">"age"</span>) &gt; <span class="number">21</span>).show()  <span class="comment">// Select people older than 21 </span></span><br><span class="line">df.select(df(<span class="string">"name"</span>), df(<span class="string">"age"</span>) + <span class="number">1</span>).show()  <span class="comment">// Select everybody, but increment the age by 1 </span></span><br><span class="line">df.groupBy(<span class="string">"age"</span>).count().show()  <span class="comment">// Count people by age</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//注册临时表</span></span><br><span class="line">df.registerTempTable(<span class="string">"df"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//对表进行操作</span></span><br><span class="line"><span class="keyword">val</span> people=sqlContext.sql(<span class="string">"sql语句"</span>)</span><br><span class="line">people.show</span><br></pre></td></tr></table></figure>
<h3 id="Parquet文件"><a href="#Parquet文件" class="headerlink" title="Parquet文件"></a>Parquet文件</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">people.write.parquet(<span class="string">"people.parquet"</span>)</span><br><span class="line"><span class="comment">//加载parquet数据源</span></span><br><span class="line"><span class="keyword">val</span> parquetFile = sqlContext.read.parquet(<span class="string">"people.parquet"</span>)</span><br><span class="line">parquetFile.registerTempTable(<span class="string">"parquetFile"</span>)</span><br><span class="line">### hive表</span><br><span class="line">```scala </span><br><span class="line">sqlcontext.sql(<span class="string">"HQL语句"</span>)</span><br></pre></td></tr></table></figure>
  </section>

  
  

<section class="post-comments">

    <div class="ds-thread" data-thread-key="2016/06/13/SparkSQL/"></div>

    <script type="text/javascript">
      var duoshuoQuery = {short_name:"yujie"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = '//static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] 
        || document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
    </script> 

</section>


</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2014-2015. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
